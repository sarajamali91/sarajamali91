{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af496623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "855cec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports library\n",
    "import numpy\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffbcece4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of data: \n",
      "(50000,)\n",
      "(50000,)\n",
      "\n",
      "Classes: \n",
      "[0 1]\n",
      "\n",
      "Number of words: \n",
      "88585\n",
      "\n",
      "Review length: \n",
      "Mean 234.76 words (172.911495)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
    "X = numpy.concatenate((X_train, X_test), axis=0)\n",
    "y = numpy.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "# summarize size\n",
    "print(); print(\"Shape of data: \")\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Summarize number of classes\n",
    "print(); print(\"Classes: \")\n",
    "print(numpy.unique(y))\n",
    "\n",
    "# Summarize number of words\n",
    "print(); print(\"Number of words: \")\n",
    "print(len(numpy.unique(numpy.hstack(X))))\n",
    "\n",
    "# Summarize review length\n",
    "print(); print(\"Review length: \")\n",
    "result = [len(x) for x in X]\n",
    "print(\"Mean %.2f words (%f)\" % (numpy.mean(result), numpy.std(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6d9a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d54d1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 250)               4000250   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,160,501\n",
      "Trainable params: 4,160,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 32s 40ms/step - loss: 0.3894 - accuracy: 0.8094 - val_loss: 0.2940 - val_accuracy: 0.8769\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.1216 - accuracy: 0.9569 - val_loss: 0.3888 - val_accuracy: 0.8575\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0256 - accuracy: 0.9912 - val_loss: 0.7115 - val_accuracy: 0.8393\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.7641 - val_accuracy: 0.8487\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.6872 - val_accuracy: 0.8481\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.8922 - val_accuracy: 0.8486\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.8188 - val_accuracy: 0.8465\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.9507 - val_accuracy: 0.8440\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 0.9881 - val_accuracy: 0.8453\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.9944 - val_accuracy: 0.8483\n",
      "\n",
      "Accuracy: 84.83%\n"
     ]
    }
   ],
   "source": [
    "# model 1\n",
    "# MLP\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(); print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "692cf1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 500, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 250, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8000)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 250)               2000250   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,163,605\n",
      "Trainable params: 2,163,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.3788 - accuracy: 0.8112 - val_loss: 0.2964 - val_accuracy: 0.8742\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 32s 40ms/step - loss: 0.1876 - accuracy: 0.9282 - val_loss: 0.2715 - val_accuracy: 0.8889\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0959 - accuracy: 0.9665 - val_loss: 0.3486 - val_accuracy: 0.8723\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 0.5033 - val_accuracy: 0.8661\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.6096 - val_accuracy: 0.8715\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 32s 40ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.6900 - val_accuracy: 0.8710\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 32s 40ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.7035 - val_accuracy: 0.8685\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 32s 40ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.6952 - val_accuracy: 0.8706\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.8239 - val_accuracy: 0.8677\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.9176 - val_accuracy: 0.8635\n",
      "\n",
      "Accuracy: 86.35%\n"
     ]
    }
   ],
   "source": [
    "# model 2\n",
    "# 1D CNN\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Conv1D(32, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(); print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
